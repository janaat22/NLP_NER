{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_Model_S.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janaat22/NLP_NER/blob/master/NER_Model_S.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrGaB4fxws8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6ka8aPGPTba",
        "colab_type": "code",
        "outputId": "94de9c33-5b65-46a5-9012-d587dda63aa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "pip install sklearn-crfsuite\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.8.6)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (4.28.1)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.9.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dsA4N1aa2bw",
        "colab_type": "code",
        "outputId": "7063fa8d-1619-4c7e-ee33-13e4d11c7be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvP9tnigoqur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thJDwo1WPRqB",
        "colab_type": "code",
        "outputId": "91a257cf-a055-44e8-92bd-91b5822a6466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O9l5LQBWW7x",
        "colab_type": "code",
        "outputId": "767748e5-464b-4417-d05b-0a5f818e9412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "nltk.download('gazetteers')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]   Package gazetteers is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jImbwdA2Yh_H",
        "colab_type": "code",
        "outputId": "9368dabd-6393-4540-d702-073dcf8f26ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "nltk.download('names')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTWW3NnewSjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import chain\n",
        "\n",
        "import nltk\n",
        "import sklearn\n",
        "import scipy.stats\n",
        "#Modeling\n",
        "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import learning_curve, GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "#from sklearn_crfsuite import CRF, scorers, metrics\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import CRF\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "from sklearn.metrics import classification_report, make_scorer\n",
        "\n",
        "from nltk.stem.porter import *\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from nltk.corpus import names, ieer, gazetteers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt5VOIA4WOUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "locations = gazetteers.words()\n",
        "locations = [x.lower() for x in locations]\n",
        "names_list = names.words()\n",
        "names_list = [x.lower() for x in names_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PI9CoHKWZej",
        "colab_type": "code",
        "outputId": "dcc972b1-d12d-4320-88f6-76039b1efaf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "word = 'LA'\n",
        "word.lower() in locations"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRc0x0xJQmI_",
        "colab_type": "code",
        "outputId": "57dac296-6564-44bb-8342-d186a0e07216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrv4xwf5Q3s4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def file_to_list(file_name):  \n",
        "  training_key_value = []\n",
        "  word_dict = {}\n",
        "  tags = {}\n",
        "  word_list = []\n",
        "  sentence = 1\n",
        "  file1 = open(file_name, 'r')\n",
        "  Lines = file1.readlines() \n",
        "  for line in Lines:    \n",
        "    training_key_value = line.split()\n",
        "    if(len(training_key_value) == 2):\n",
        "      word = training_key_value[0]\n",
        "      tag = training_key_value[1]\n",
        "      word_dict[word] = tag\n",
        "      tokenized = nltk.word_tokenize(word)\n",
        "      tagged = nltk.pos_tag(tokenized)\n",
        "      word_list.append(([sentence, word, tagged[0][1], tag])) \n",
        "      tags.update(tagged)\n",
        "    else:\n",
        "      sentence = sentence + 1\n",
        "    file1.close()\n",
        "  return word_dict,word_list\n",
        "\n",
        "#Train data\n",
        "word_dict_train, word_list_train = file_to_list('train.txt')\n",
        "# print(word_dict_train.keys())\n",
        "# array_of_words_train = np.array(list(word_dict_train.keys()))\n",
        "# array_of_values_train = np.array(list(word_dict_train.values()))\n",
        "# X_Y_train = np.column_stack((array_of_words_train, array_of_values_train))\n",
        "\n",
        "#Dev data\n",
        "word_dict_dev,word_list_dev = file_to_list('dev.txt')\n",
        "# array_of_words_dev = np.array(list(word_dict_dev.keys()))\n",
        "# array_of_values_dev = np.array(list(word_dict_dev.values()))\n",
        "# X_Y_dev = np.column_stack((array_of_words_dev, array_of_values_dev))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l66r5zeKounW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def file_to_list_test(file_name):  \n",
        "  training_key_value = []\n",
        "  word_dict = {}  \n",
        "  word_list = []\n",
        "  training_key_value = [] \n",
        "  test_word_list = []\n",
        "  file1 = open(file_name, 'r')\n",
        "  sentence_num = 1\n",
        "  Lines = file1.readlines() \n",
        "  # print(\"print\" + str(len(Lines[11].split('\\n'))))\n",
        "  for line in Lines:    \n",
        "    if(len(line) > 1):      \n",
        "      word = line.replace('\\n', '')\n",
        "      tokenized = nltk.word_tokenize(word)\n",
        "      tagged = nltk.pos_tag(tokenized)\n",
        "      # print(sentence_num)\n",
        "      test_word_list.append(([sentence_num, word, tagged[0][1]]))\n",
        "    else:\n",
        "      # print(\"\\nelse\")\n",
        "      sentence_num = sentence_num + 1\n",
        "  file1.close()\n",
        "  return test_word_list\n",
        "\n",
        "\n",
        "\n",
        "#Test data\n",
        "word_list_test = file_to_list_test('test_no_tag.txt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0rkLgvaS1U8",
        "colab_type": "code",
        "outputId": "acbdc171-1434-405c-82a8-dcc5720dcc5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "train_data = pd.DataFrame(word_list_train)\n",
        "print(train_data.head(n = 4))\n",
        "\n",
        "dev_data = pd.DataFrame(word_list_dev)\n",
        "print(dev_data.head(n = 4))\n",
        "\n",
        "\n",
        "test_data = pd.DataFrame(word_list_test)\n",
        "print(test_data.head(n = 4))\n",
        "# print(word_list_test)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0                1    2  3\n",
            "0  1  @SammieLynnsMom   NN  O\n",
            "1  1         @tg10781   NN  O\n",
            "2  1             they  PRP  O\n",
            "3  1             will   MD  O\n",
            "   0       1   2  3\n",
            "0  1    STOP  NN  O\n",
            "1  1    WHAT  WP  O\n",
            "2  1  YOU'RE  NN  O\n",
            "3  1   DOING  NN  O\n",
            "   0       1    2\n",
            "0  1      We  PRP\n",
            "1  1     're  VBP\n",
            "2  1  slaves  NNS\n",
            "3  1      to   TO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ji8x2h_UjQ0",
        "colab_type": "code",
        "outputId": "f5366149-9eea-4e12-ab27-140132ec10be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "# train_data.columns = train_data.iloc[0]\n",
        "# train_data = train_data[1:]\n",
        "train_data.columns = ['Sentence','Word','POS','Tag']\n",
        "# train_data = train_data.reset_index(drop=True)\n",
        "#train_data.head(n=5)\n",
        "\n",
        "# dev_data.columns = dev_data.iloc[0]\n",
        "# dev_data = dev_data[1:]\n",
        "dev_data.columns = ['Sentence','Word','POS','Tag']\n",
        "# dev_data = dev_data.reset_index(drop=True)\n",
        "#dev_data.head(n=5)\n",
        "\n",
        "# test_data.columns = test_data.iloc[0]\n",
        "# test_data = test_data[1:]\n",
        "test_data.columns = ['Sentence','Word','POS']\n",
        "# test_data = test_data.reset_index(drop=True)\n",
        "test_data.head(n= 10)\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>We</td>\n",
              "      <td>PRP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>'re</td>\n",
              "      <td>VBP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>slaves</td>\n",
              "      <td>NNS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>DT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>world</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>we</td>\n",
              "      <td>PRP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>mastered</td>\n",
              "      <td>VBN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2</td>\n",
              "      <td>I</td>\n",
              "      <td>PRP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentence      Word  POS\n",
              "0         1        We  PRP\n",
              "1         1       're  VBP\n",
              "2         1    slaves  NNS\n",
              "3         1        to   TO\n",
              "4         1         a   DT\n",
              "5         1     world   NN\n",
              "6         1        we  PRP\n",
              "7         1  mastered  VBN\n",
              "8         1         .    .\n",
              "9         2         I  PRP"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_9RMWAP1JO5",
        "colab_type": "code",
        "outputId": "810124be-465d-4af4-d0b9-07040ff5d6e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42413, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkRTyTd9Uo9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A class to retrieve the sentences from the dataset\n",
        "class getsentence(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1.0\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "\n",
        "class getsentence_ForTest(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1.0\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p) for w, p in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist())\n",
        "                                                      ]\n",
        "        self.grouped = self.data.groupby(\"Sentence\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7FvegeoWp-5",
        "colab_type": "code",
        "outputId": "43c61c17-9a74-4f9c-f61c-5387e4a717cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "train_getter = getsentence(train_data)\n",
        "train_sentences = train_getter.sentences\n",
        "\n",
        "dev_getter = getsentence(dev_data)\n",
        "dev_sentences = dev_getter.sentences\n",
        "\n",
        "test_getter = getsentence_ForTest(test_data)\n",
        "test_sentences = test_getter.sentences\n",
        "\n",
        "#This is how a sentence will look like. \n",
        "print(train_sentences[0])"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('@SammieLynnsMom', 'NN', 'O'), ('@tg10781', 'NN', 'O'), ('they', 'PRP', 'O'), ('will', 'MD', 'O'), ('be', 'VB', 'O'), ('all', 'DT', 'O'), ('done', 'VBN', 'O'), ('by', 'IN', 'O'), ('Sunday', 'NNP', 'O'), ('trust', 'NN', 'O'), ('me', 'PRP', 'O'), ('*wink*', 'NN', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bZI96NRXMJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "# Feature set\n",
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "    \n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        'postag[:2]': postag[:2],\n",
        "        'inLocations': word.lower() in locations if not word.find('#') else word.lower().replace('#','') in locations,\n",
        "        'inNames' : word.lower() in names_list if not word.find('@') else word.lower().replace('@','') in names_list,\n",
        "        'isTag' : word.find('@'),\n",
        "        'hasCapitalLetter' : word[0].isupper(),\n",
        "        # 'stem' : stemmer.stem(word),        \n",
        "        'lemma' : lemmatizer.lemmatize(word),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            '-1:postag': postag1,\n",
        "            '-1:postag[:2]': postag1[:2],\n",
        "            '-1:inLocations': word1.lower() in locations if not word1.find('#') else word1.lower().replace('#','') in locations,\n",
        "            '-1:inNames' : word1.lower() in names_list if not word1.find('@') else word1.lower().replace('@','') in names_list,\n",
        "            '-1:hasCapitalLetter' : word1[0].isupper(),\n",
        "            # '-1:stem' : stemmer.stem(word1),            \n",
        "            '-1:lemma' : lemmatizer.lemmatize(word1),\n",
        "             \n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            '+1:postag': postag1,\n",
        "            '+1:postag[:2]': postag1[:2],\n",
        "            '+1:inLocations': word1.lower() in locations if not word1.find('#') else word1.lower().replace('#','') in locations,\n",
        "            '+1:inNames' :word1.lower() in names_list if not word1.find('@') else word1.lower().replace('@','') in names_list,\n",
        "            '+1:hasCapitalLetter' : word1[0].isupper(),\n",
        "            # '+1:stem' : stemmer.stem(word1),            \n",
        "            '+1:lemma' : lemmatizer.lemmatize(word),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viReG1-QHWmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDRJbpFeqDxp",
        "colab_type": "code",
        "outputId": "8942a87e-77f3-47e5-eee5-132e5643321a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "print(test_sentences[5])\n",
        "sent2features(train_sentences[3])[0]\n",
        "# sent2features(test_sentences[7])[0]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Happy', 'JJ'), ('v-day', 'NN'), ('ðŸ˜Œ', 'NN'), ('â¤', 'NN'), ('ï¸', 'NN'), ('ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚', 'NN'), ('#noshame', '#')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'+1:hasCapitalLetter': False,\n",
              " '+1:inLocations': False,\n",
              " '+1:inNames': False,\n",
              " '+1:lemma': '@ls_n',\n",
              " '+1:postag': 'RB',\n",
              " '+1:postag[:2]': 'RB',\n",
              " '+1:word.istitle()': False,\n",
              " '+1:word.isupper()': False,\n",
              " '+1:word.lower()': 'perhaps',\n",
              " 'BOS': True,\n",
              " 'bias': 1.0,\n",
              " 'hasCapitalLetter': False,\n",
              " 'inLocations': False,\n",
              " 'inNames': False,\n",
              " 'isTag': 0,\n",
              " 'lemma': '@ls_n',\n",
              " 'postag': 'NN',\n",
              " 'postag[:2]': 'NN',\n",
              " 'word.isdigit()': False,\n",
              " 'word.istitle()': False,\n",
              " 'word.isupper()': False,\n",
              " 'word.lower()': '@ls_n',\n",
              " 'word[-2:]': '_n',\n",
              " 'word[-3:]': 's_n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBmR_UsEW5YZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating the train and test set\n",
        "\n",
        "X_train = [sent2features(s) for s in train_sentences]\n",
        "y_train = [sent2labels(s) for s in train_sentences]\n",
        "\n",
        "X_dev = [sent2features(s) for s in dev_sentences]\n",
        "y_dev = [sent2labels(s) for s in dev_sentences]\n",
        "\n",
        "X_test = [sent2features(s) for s in test_sentences]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UleMIHP0X6Q2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating the CRF model\n",
        "crf = CRF(algorithm='lbfgs',\n",
        "          c1=0.1,\n",
        "          c2=0.1,\n",
        "          max_iterations=100,\n",
        "          all_possible_transitions=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5xOekAmX9V8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crf = crf.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzYVpfgI1ed2",
        "colab_type": "code",
        "outputId": "58a6963b-2fd4-40fe-c64d-656182295ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "pred = cross_val_predict(estimator=crf, X = X_train,y = y_train, cv=10)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwRdHqK72JXv",
        "colab_type": "code",
        "outputId": "af36333c-53b0-408d-bfe8-c62c62cf29fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "#evaluate the model\n",
        "report = flat_classification_report(y_pred=pred, y_true=y_train)\n",
        "print(report)\n",
        "# f1 = metrics.flat_f1_score(y_train, y_pred, average='weighted', labels=labels)\n",
        "# print(\"F1 weighted avg: \" + str(f1))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   B-company       0.87      0.46      0.60       171\n",
            "     B-group       0.67      0.19      0.29       106\n",
            "  B-location       0.77      0.54      0.63       380\n",
            "     B-other       0.53      0.24      0.33       225\n",
            "    B-person       0.79      0.64      0.71       449\n",
            "   B-product       0.79      0.20      0.31        97\n",
            "     B-title       0.54      0.22      0.31        68\n",
            "   I-company       0.57      0.11      0.19        36\n",
            "     I-group       0.52      0.14      0.22        84\n",
            "  I-location       0.59      0.36      0.45       154\n",
            "     I-other       0.47      0.29      0.36       320\n",
            "    I-person       0.78      0.71      0.74       215\n",
            "   I-product       0.70      0.17      0.28        80\n",
            "     I-title       0.46      0.21      0.29        77\n",
            "           O       0.97      0.99      0.98     44007\n",
            "\n",
            "    accuracy                           0.96     46469\n",
            "   macro avg       0.67      0.37      0.45     46469\n",
            "weighted avg       0.96      0.96      0.96     46469\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POk26KMItTJs",
        "colab_type": "code",
        "outputId": "a4cf1048-bdf0-4d64-c6bd-0ed0d90e735b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# labels = list(crf.classes_)\n",
        "\n",
        "# labels.remove('O')\n",
        "print(labels)\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['B-location', 'I-location', 'B-title', 'I-title', 'B-company', 'B-product', 'B-person', 'B-other', 'I-other', 'B-group', 'I-group', 'I-product', 'I-company', 'I-person']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybkKJgm949gA",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bQ09BiitZR4",
        "colab_type": "code",
        "outputId": "f7b75685-e374-4d69-a973-b29007e1bd0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "y_pred = crf.predict(X_dev)\n",
        "metrics.flat_f1_score(y_dev, y_pred,\n",
        "                      average='weighted', labels=labels)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31361687449049797"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6QeV_Ottu5O",
        "colab_type": "code",
        "outputId": "716cc7ee-45c9-4239-c40b-7f34f3ed83c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "source": [
        "# group B and I results\n",
        "sorted_labels = sorted(\n",
        "    labels,\n",
        "    key=lambda name: (name[1:], name[0])\n",
        ")\n",
        "print(metrics.flat_classification_report(\n",
        "    y_dev, y_pred, labels=sorted_labels, digits=3\n",
        "))\n",
        "\n",
        "accuracy = metrics.flat_accuracy_score(y_dev, y_pred)\n",
        "print(\"Accuracy: \" + str(accuracy))\n",
        "f1 = metrics.flat_f1_score(y_dev, y_pred, average='weighted', labels=labels)\n",
        "precision = metrics.flat_precision_score(y_dev, y_pred, average='weighted', labels=labels)\n",
        "print(\"Precision : \"  + str(precision))\n",
        "\n",
        "recall = metrics.flat_recall_score(y_dev, y_pred, average='weighted', labels=labels)\n",
        "print(\"Recall : \" + str(recall))\n",
        "print(\"F1 weighted avg: \" + str(f1))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   B-company      0.462     0.154     0.231        39\n",
            "   I-company      0.000     0.000     0.000        10\n",
            "     B-group      0.500     0.045     0.083       111\n",
            "     I-group      0.143     0.021     0.036        48\n",
            "  B-location      0.612     0.461     0.526       154\n",
            "  I-location      0.557     0.420     0.479        81\n",
            "     B-other      0.462     0.182     0.261       132\n",
            "     I-other      0.188     0.289     0.228        97\n",
            "    B-person      0.624     0.515     0.564       171\n",
            "    I-person      0.588     0.600     0.594        95\n",
            "   B-product      1.000     0.027     0.053        37\n",
            "   I-product      0.000     0.000     0.000       121\n",
            "     B-title      0.167     0.059     0.087        17\n",
            "     I-title      0.111     0.067     0.083        15\n",
            "\n",
            "   micro avg      0.476     0.281     0.353      1128\n",
            "   macro avg      0.387     0.203     0.230      1128\n",
            "weighted avg      0.446     0.281     0.314      1128\n",
            "\n",
            "Accuracy: 0.9406555562388537\n",
            "Precision : 0.4458889325321852\n",
            "Recall : 0.28102836879432624\n",
            "F1 weighted avg: 0.31361687449049797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncsWQQu1xMJu",
        "colab_type": "text"
      },
      "source": [
        "# Hyper Parameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4_KUUszxQie",
        "colab_type": "code",
        "outputId": "15646554-0ba0-4afe-a769-7b4eb3bd8ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "Model_X = CRF(\n",
        "    algorithm='lbfgs',\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "params_space = {\n",
        "    'c1': scipy.stats.expon(scale=0.5),\n",
        "    'c2': scipy.stats.expon(scale=0.05),\n",
        "}\n",
        "\n",
        "# use the same metric for evaluation\n",
        "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
        "                        average='weighted', labels=labels)\n",
        "\n",
        "# search\n",
        "rs = RandomizedSearchCV(crf, params_space,\n",
        "                        cv=3,\n",
        "                        verbose=1,\n",
        "                        n_jobs=-1,\n",
        "                        n_iter=50,\n",
        "                        scoring=f1_scorer)\n",
        "rs.fit(X_train, y_train)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 11.2min\n",
            "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 35.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
              "                                 all_possible_transitions=False, averaging=None,\n",
              "                                 c=None, c1=0.1, c2=0.1,\n",
              "                                 calibration_candidates=None,\n",
              "                                 calibration_eta=None,\n",
              "                                 calibration_max_trials=None,\n",
              "                                 calibration_rate=None,\n",
              "                                 calibration_samples=None, delta=None,\n",
              "                                 epsilon=None, error_sensitive=None, gamma=None,\n",
              "                                 keep_t...\n",
              "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7faa4c5d6d30>},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False,\n",
              "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=['B-location', 'I-location', 'B-title', 'I-title', 'B-company', 'B-product', 'B-person', 'B-other', 'I-other', 'B-group', 'I-group', 'I-product', 'I-company', 'I-person']),\n",
              "                   verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en-V95Voyknk",
        "colab_type": "text"
      },
      "source": [
        "# Best Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNKWqjduynlm",
        "colab_type": "code",
        "outputId": "0eb1be83-7f01-44c8-a0dc-33ca0e656d5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "print('best params:', rs.best_params_)\n",
        "print('best CV score:', rs.best_score_)\n",
        "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best params: {'c1': 0.13208146892209183, 'c2': 0.003605084094505999}\n",
            "best CV score: 0.46883084031421807\n",
            "model size: 0.73M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx3EuRlo5kvv",
        "colab_type": "code",
        "outputId": "bd454bc5-23b4-4e28-cc0c-aca95b60eef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "crf = rs.best_estimator_\n",
        "y_pred = crf.predict(X_dev)\n",
        "print(metrics.flat_classification_report(\n",
        "    y_dev, y_pred, labels=sorted_labels, digits=3\n",
        "))\n",
        "\n",
        "accuracy = metrics.flat_accuracy_score(y_dev, y_pred)\n",
        "print(\"accuracy :\" + str(accuracy))\n",
        "precision = metrics.flat_precision_score(y_dev, y_pred, average='weighted', labels=labels)\n",
        "print(\"Precision : \"  + str(precision))\n",
        "recall = metrics.flat_recall_score(y_dev, y_pred, average='weighted', labels=labels)\n",
        "print(\"Recall : \" + str(recall))\n",
        "f1 = metrics.flat_f1_score(y_dev, y_pred, average='weighted', labels=labels)\n",
        "print(\"F1 weighted avg: \" + str(f1))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   B-company      0.500     0.154     0.235        39\n",
            "   I-company      0.000     0.000     0.000        10\n",
            "     B-group      0.500     0.054     0.098       111\n",
            "     I-group      0.200     0.021     0.038        48\n",
            "  B-location      0.568     0.461     0.509       154\n",
            "  I-location      0.571     0.444     0.500        81\n",
            "     B-other      0.438     0.212     0.286       132\n",
            "     I-other      0.181     0.309     0.228        97\n",
            "    B-person      0.537     0.515     0.525       171\n",
            "    I-person      0.558     0.611     0.583        95\n",
            "   B-product      1.000     0.108     0.195        37\n",
            "   I-product      1.000     0.017     0.033       121\n",
            "     B-title      0.000     0.000     0.000        17\n",
            "     I-title      0.000     0.000     0.000        15\n",
            "\n",
            "   micro avg      0.446     0.293     0.353      1128\n",
            "   macro avg      0.432     0.208     0.231      1128\n",
            "weighted avg      0.529     0.293     0.316      1128\n",
            "\n",
            "accuracy :0.9379496955906771\n",
            "Precision : 0.5287009765597402\n",
            "Recall : 0.2925531914893617\n",
            "F1 weighted avg: 0.3164102067099719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVLpN_ce61Ze",
        "colab_type": "code",
        "outputId": "6d108e9e-26dd-4060-c44b-093b59d67942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "\n",
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
        "\n",
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top likely transitions:\n",
            "B-group -> I-group 9.396314\n",
            "B-title -> I-title 9.289197\n",
            "B-product -> I-product 8.864227\n",
            "B-person -> I-person 8.337055\n",
            "I-group -> I-group 7.989319\n",
            "I-title -> I-title 7.976070\n",
            "B-other -> I-other 7.774106\n",
            "B-location -> I-location 7.661786\n",
            "I-product -> I-product 7.482547\n",
            "B-company -> I-company 7.256505\n",
            "I-company -> I-company 6.725760\n",
            "I-other -> I-other 6.361689\n",
            "I-location -> I-location 5.916330\n",
            "I-person -> I-person 5.322534\n",
            "O      -> O       4.013160\n",
            "O      -> B-person 2.490924\n",
            "O      -> B-company 2.432572\n",
            "O      -> B-product 2.225317\n",
            "O      -> B-title 1.883259\n",
            "O      -> B-group 1.780581\n",
            "\n",
            "Top unlikely transitions:\n",
            "B-company -> O       0.327161\n",
            "B-person -> O       0.289483\n",
            "B-group -> O       0.157608\n",
            "I-person -> O       0.072233\n",
            "I-company -> B-location 0.064935\n",
            "B-product -> O       0.021644\n",
            "I-location -> B-group 0.019760\n",
            "I-title -> O       -0.150863\n",
            "B-other -> O       -0.159177\n",
            "B-location -> B-location -0.177735\n",
            "I-group -> O       -0.192949\n",
            "I-product -> O       -0.239930\n",
            "B-location -> O       -0.265149\n",
            "I-company -> O       -0.350837\n",
            "I-other -> O       -0.497837\n",
            "I-location -> O       -0.523833\n",
            "I-other -> B-other -0.541151\n",
            "B-title -> O       -0.714629\n",
            "I-location -> B-location -0.854805\n",
            "I-other -> B-person -1.341600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh3d0PMU7HpF",
        "colab_type": "code",
        "outputId": "8e0be551-8f39-4216-e076-2bcddada94ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def print_state_features(state_features):\n",
        "    for (attr, label), weight in state_features:\n",
        "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
        "\n",
        "print(\"Top positive:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common(30))\n",
        "\n",
        "print(\"\\nTop negative:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top positive:\n",
            "12.179724 B-company word.lower():twitter\n",
            "10.221582 B-product word.lower():ipod\n",
            "9.816257 B-company word.lower():facebook\n",
            "8.817285 B-person word.lower():pope\n",
            "7.030279 I-other  -1:word.lower():fashion\n",
            "6.752532 B-other  word[-2:]:BL\n",
            "6.572125 B-product word.lower():xbox\n",
            "6.314450 B-product word.lower():ipad\n",
            "5.756496 B-group  +1:word.lower():gear\n",
            "5.681476 B-other  word[-2:]:GP\n",
            "5.619877 B-company word.lower():youtube\n",
            "5.555898 B-person word.lower():eminem\n",
            "5.487478 B-other  word[-3:]:mas\n",
            "5.269280 B-location word[-3:]:ham\n",
            "5.047971 O        +1:word.lower():bless\n",
            "5.008578 B-person word.lower():taylor\n",
            "4.901854 B-group  -1:lemma:Go\n",
            "4.868173 O        EOS\n",
            "4.583040 I-location word.lower():lounge\n",
            "4.522804 B-location inLocations\n",
            "4.502677 B-company +1:word.lower():instant\n",
            "4.380057 B-person word[-3:]:nem\n",
            "4.376621 B-location +1:word.lower():tall\n",
            "4.269842 I-other  word.lower():festival\n",
            "4.265163 O        bias\n",
            "4.253721 B-location +1:word.lower():winds\n",
            "4.194503 B-location word.lower():uk\n",
            "3.973192 B-company word[-3:]:zon\n",
            "3.964048 B-location word[-3:]:nia\n",
            "3.958878 I-group  +1:word.lower():yeah\n",
            "\n",
            "Top negative:\n",
            "-2.283723 O        word.lower():london\n",
            "-2.313950 O        word[-3:]:rks\n",
            "-2.344373 O        word[-3:]:ERS\n",
            "-2.390935 O        word[-2:]:ix\n",
            "-2.412206 O        -1:word.lower():john\n",
            "-2.425454 O        word[-2:]:GP\n",
            "-2.490525 B-person inLocations\n",
            "-2.516031 O        -1:lemma:national\n",
            "-2.518869 O        +1:word.lower():song\n",
            "-2.529406 O        +1:word.lower():full\n",
            "-2.562257 O        word[-2:]:LE\n",
            "-2.591851 O        +1:word.lower():family\n",
            "-2.691295 O        word.lower():club\n",
            "-2.859989 O        word[-2:]:ka\n",
            "-2.869650 O        word[-2:]:ni\n",
            "-2.953051 O        word[-3:]:nte\n",
            "-3.032561 O        -1:word.lower():dj\n",
            "-3.214584 O        -1:word.lower():does\n",
            "-3.244633 I-location -1:inLocations\n",
            "-3.260024 O        hasCapitalLetter\n",
            "-3.289254 O        word[-2:]:OS\n",
            "-3.290293 O        +1:word.lower():live\n",
            "-3.477006 O        word[-2:]:mi\n",
            "-3.736428 O        -1:lemma:green\n",
            "-3.769635 O        +1:word.lower():v\n",
            "-3.855851 O        word[-2:]:BB\n",
            "-3.962662 O        word[-3:]:ggy\n",
            "-4.164420 O        word[-3:]:lds\n",
            "-4.201241 O        +1:word.lower():!!!!!!!\n",
            "-4.392668 O        word[-3:]:ube\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8OxPL0ZNKgz",
        "colab_type": "code",
        "outputId": "0a8f6c74-7b2e-4e93-cc44-4421e2b845dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "crf = rs.best_estimator_\n",
        "y_pred = crf.predict(X_test)\n",
        "print(y_pred[0][0])"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNi_HAyDT8lb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outR = open(\"test_no_tag.txt\", \"r\")\n",
        "outF = open(\"result.txt\", \"w\")\n",
        "lines = outR.readlines()\n",
        "pred_line = 0\n",
        "pred_word = 0\n",
        "for line in lines:\n",
        "  if(len(line)>1):\n",
        "    outF.write(line.replace('\\n','')+\"\\t\\t\"+y_pred[pred_line][pred_word]+\"\\n\")\n",
        "    pred_word = pred_word + 1\n",
        "  else:\n",
        "    outF.write(\"\\n\")\n",
        "    pred_word = 0\n",
        "    pred_line = pred_line + 1\n",
        "\n",
        "\n",
        "outR.close()\n",
        "outF.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57o2LDnds9iW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
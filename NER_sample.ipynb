{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_sample.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPtOI4PVQJhmV3bNCiacIVw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janaat22/NLP_NER/blob/master/NER_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrGaB4fxws8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6ka8aPGPTba",
        "colab_type": "code",
        "outputId": "0ed3e3e1-17d4-455e-827c-e9ee3877559a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "pip install sklearn-crfsuite\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.9.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (1.12.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.8.6)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dsA4N1aa2bw",
        "colab_type": "code",
        "outputId": "94451e44-a5d9-4ca7-ba8f-50057b9154d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thJDwo1WPRqB",
        "colab_type": "code",
        "outputId": "19830586-c255-4685-9832-6dc787aa95d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 376
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O9l5LQBWW7x",
        "colab_type": "code",
        "outputId": "72702e96-69e9-4f97-e49a-cf41e6821619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "nltk.download('gazetteers')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]   Package gazetteers is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 377
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jImbwdA2Yh_H",
        "colab_type": "code",
        "outputId": "d60793de-cdee-449f-d2bd-a57628859c4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "nltk.download('names')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 378
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTWW3NnewSjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import chain\n",
        "\n",
        "import nltk\n",
        "import sklearn\n",
        "import scipy.stats\n",
        "#Modeling\n",
        "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import learning_curve, GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "#from sklearn_crfsuite import CRF, scorers, metrics\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import CRF\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "from sklearn.metrics import classification_report, make_scorer\n",
        "\n",
        "from nltk.stem.porter import *\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from nltk.corpus import names, ieer, gazetteers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt5VOIA4WOUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "locations = gazetteers.words()\n",
        "locations = [x.lower() for x in locations]\n",
        "names_list = names.words()\n",
        "names_list = [x.lower() for x in names_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PI9CoHKWZej",
        "colab_type": "code",
        "outputId": "19cbbd8a-1aa0-4015-e2c7-c5a82379979e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word = 'LA'\n",
        "word.lower() in locations"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 381
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRc0x0xJQmI_",
        "colab_type": "code",
        "outputId": "46eb794f-737e-4405-bead-bc46f3aece12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 382
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrv4xwf5Q3s4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def file_to_list(file_name):  \n",
        "  training_key_value = []\n",
        "  word_dict = {}\n",
        "  tags = {}\n",
        "  word_list = []\n",
        "  sentence = 1\n",
        "  file1 = open(file_name, 'r')\n",
        "  Lines = file1.readlines() \n",
        "  for line in Lines:    \n",
        "    training_key_value = line.split()\n",
        "    if(len(training_key_value) == 2):\n",
        "      word = training_key_value[0]\n",
        "      tag = training_key_value[1]\n",
        "      word_dict[word] = tag\n",
        "      tokenized = nltk.word_tokenize(word)\n",
        "      tagged = nltk.pos_tag(tokenized)\n",
        "      word_list.append(([sentence, word, tagged[0][1], tag])) \n",
        "      tags.update(tagged)\n",
        "    else:\n",
        "      sentence = sentence + 1\n",
        "    file1.close()\n",
        "  return word_dict,word_list\n",
        "\n",
        "#Train data\n",
        "word_dict_train, word_list_train = file_to_list('train.txt')\n",
        "# print(word_dict_train.keys())\n",
        "# array_of_words_train = np.array(list(word_dict_train.keys()))\n",
        "# array_of_values_train = np.array(list(word_dict_train.values()))\n",
        "# X_Y_train = np.column_stack((array_of_words_train, array_of_values_train))\n",
        "\n",
        "#Dev data\n",
        "word_dict_dev,word_list_dev = file_to_list('dev.txt')\n",
        "# array_of_words_dev = np.array(list(word_dict_dev.keys()))\n",
        "# array_of_values_dev = np.array(list(word_dict_dev.values()))\n",
        "# X_Y_dev = np.column_stack((array_of_words_dev, array_of_values_dev))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l66r5zeKounW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def file_to_list_test(file_name):  \n",
        "  training_key_value = []\n",
        "  word_dict = {}  \n",
        "  word_list = []\n",
        "  training_key_value = [] \n",
        "  test_word_list = []\n",
        "  file1 = open(file_name, 'r')\n",
        "  sentence_num = 1\n",
        "  Lines = file1.readlines() \n",
        "  # print(\"print\" + str(len(Lines[11].split('\\n'))))\n",
        "  for line in Lines:    \n",
        "    if(len(line.split()) > 0):      \n",
        "      word = line.replace('\\n', '')\n",
        "      tokenized = nltk.word_tokenize(word)\n",
        "      tagged = nltk.pos_tag(tokenized)\n",
        "      # print(sentence_num)\n",
        "      test_word_list.append(([sentence_num, word, tagged[0][1]]))\n",
        "    else:\n",
        "      # print(\"\\nelse\")\n",
        "      sentence_num = sentence_num + 1\n",
        "  file1.close()\n",
        "  return test_word_list\n",
        "\n",
        "\n",
        "\n",
        "#Test data\n",
        "word_list_test = file_to_list_test('test_no_tag.txt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0rkLgvaS1U8",
        "colab_type": "code",
        "outputId": "f2829d0b-2f07-4d55-f0c5-b5d9503b744c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "train_data = pd.DataFrame(word_list_train)\n",
        "print(train_data.head(n = 4))\n",
        "\n",
        "dev_data = pd.DataFrame(word_list_dev)\n",
        "print(dev_data.head(n = 4))\n",
        "\n",
        "\n",
        "test_data = pd.DataFrame(word_list_test)\n",
        "print(test_data.head(n = 4))\n",
        "# print(word_list_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0                1    2  3\n",
            "0  1  @SammieLynnsMom   NN  O\n",
            "1  1         @tg10781   NN  O\n",
            "2  1             they  PRP  O\n",
            "3  1             will   MD  O\n",
            "   0       1   2  3\n",
            "0  1    STOP  NN  O\n",
            "1  1    WHAT  WP  O\n",
            "2  1  YOU'RE  NN  O\n",
            "3  1   DOING  NN  O\n",
            "   0       1    2\n",
            "0  1      We  PRP\n",
            "1  1     're  VBP\n",
            "2  1  slaves  NNS\n",
            "3  1      to   TO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ji8x2h_UjQ0",
        "colab_type": "code",
        "outputId": "1d1e1d6c-afc6-4465-9e72-fbf01dfb733e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "train_data.columns = train_data.iloc[0]\n",
        "train_data = train_data[1:]\n",
        "train_data.columns = ['Sentence','Word','POS','Tag']\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "#train_data.head(n=5)\n",
        "\n",
        "dev_data.columns = dev_data.iloc[0]\n",
        "dev_data = dev_data[1:]\n",
        "dev_data.columns = ['Sentence','Word','POS','Tag']\n",
        "dev_data = dev_data.reset_index(drop=True)\n",
        "#dev_data.head(n=5)\n",
        "\n",
        "test_data.columns = test_data.iloc[0]\n",
        "test_data = test_data[1:]\n",
        "test_data.columns = ['Sentence','Word','POS']\n",
        "test_data = test_data.reset_index(drop=True)\n",
        "test_data.head(n= 10)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>'re</td>\n",
              "      <td>VBP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>slaves</td>\n",
              "      <td>NNS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>DT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>world</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>we</td>\n",
              "      <td>PRP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>mastered</td>\n",
              "      <td>VBN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>I</td>\n",
              "      <td>PRP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2</td>\n",
              "      <td>want</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentence      Word  POS\n",
              "0         1       're  VBP\n",
              "1         1    slaves  NNS\n",
              "2         1        to   TO\n",
              "3         1         a   DT\n",
              "4         1     world   NN\n",
              "5         1        we  PRP\n",
              "6         1  mastered  VBN\n",
              "7         1         .    .\n",
              "8         2         I  PRP\n",
              "9         2      want   NN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 386
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_9RMWAP1JO5",
        "colab_type": "code",
        "outputId": "fb29c56d-f027-45e3-c17f-b7792c716f68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42412, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 387
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkRTyTd9Uo9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A class to retrieve the sentences from the dataset\n",
        "class getsentence(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1.0\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "\n",
        "class getsentence_ForTest(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1.0\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p) for w, p in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist())\n",
        "                                                      ]\n",
        "        self.grouped = self.data.groupby(\"Sentence\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7FvegeoWp-5",
        "colab_type": "code",
        "outputId": "07f871fc-7423-49bc-be49-c62cea219282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "train_getter = getsentence(train_data)\n",
        "train_sentences = train_getter.sentences\n",
        "\n",
        "dev_getter = getsentence(dev_data)\n",
        "dev_sentences = dev_getter.sentences\n",
        "\n",
        "test_getter = getsentence_ForTest(test_data)\n",
        "test_sentences = test_getter.sentences\n",
        "\n",
        "#This is how a sentence will look like. \n",
        "print(train_sentences[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('@tg10781', 'NN', 'O'), ('they', 'PRP', 'O'), ('will', 'MD', 'O'), ('be', 'VB', 'O'), ('all', 'DT', 'O'), ('done', 'VBN', 'O'), ('by', 'IN', 'O'), ('Sunday', 'NNP', 'O'), ('trust', 'NN', 'O'), ('me', 'PRP', 'O'), ('*wink*', 'NN', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bZI96NRXMJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "# Feature set\n",
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "    \n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        # 'word.lower()': word.lower(),\n",
        "        # 'word[-3:]': word[-3:],\n",
        "        # 'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        'postag[:2]': postag[:2],\n",
        "        'inLocations': word.lower() in locations,\n",
        "        'inNames' : word.lower() in names_list,\n",
        "        'isTag' : word.find('@'),\n",
        "        'hasCapitalLetter' : word[0].isupper(),\n",
        "        'stem' : stemmer.stem(word),        \n",
        "        # 'lemma' : lemmatizer.lemmatize(word),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            # '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            '-1:postag': postag1,\n",
        "            '-1:postag[:2]': postag1[:2],\n",
        "            '-1:inLocations': word1.lower() in locations,\n",
        "            '-1:inNames' : word1.lower() in names_list,\n",
        "            '-1:hasCapitalLetter' : word1[0].isupper(),\n",
        "            '-1:stem' : stemmer.stem(word1),            \n",
        "            # '-1:lemma' : lemmatizer.lemmatize(word1),\n",
        "             \n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.update({\n",
        "            # '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            '+1:postag': postag1,\n",
        "            '+1:postag[:2]': postag1[:2],\n",
        "            '+1:inLocations': word1.lower() in locations,\n",
        "            '+1:inNames' : word1.lower() in names_list,\n",
        "            '+1:hasCapitalLetter' : word1[0].isupper(),\n",
        "            '+1:stem' : stemmer.stem(word1),            \n",
        "            # '+1:lemma' : lemmatizer.lemmatize(word),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viReG1-QHWmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDRJbpFeqDxp",
        "colab_type": "code",
        "outputId": "872a8418-d71e-4360-fb88-1f7c162c6a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "print(test_sentences[5])\n",
        "sent2features(train_sentences[3])[0]\n",
        "# sent2features(test_sentences[7])[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Happy', 'JJ'), ('v-day', 'NN'), ('ðŸ˜Œ', 'NN'), ('â¤', 'NN'), ('ï¸', 'NN'), ('ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚', 'NN'), ('#noshame', '#')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'+1:hasCapitalLetter': False,\n",
              " '+1:inLocations': False,\n",
              " '+1:inNames': False,\n",
              " '+1:postag': 'RB',\n",
              " '+1:postag[:2]': 'RB',\n",
              " '+1:stem': 'perhap',\n",
              " '+1:word.istitle()': False,\n",
              " '+1:word.isupper()': False,\n",
              " 'BOS': True,\n",
              " 'bias': 1.0,\n",
              " 'hasCapitalLetter': False,\n",
              " 'inLocations': False,\n",
              " 'inNames': False,\n",
              " 'isTag': 0,\n",
              " 'postag': 'NN',\n",
              " 'postag[:2]': 'NN',\n",
              " 'stem': '@ls_n',\n",
              " 'word.isdigit()': False,\n",
              " 'word.istitle()': False,\n",
              " 'word.isupper()': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 391
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBmR_UsEW5YZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating the train and test set\n",
        "\n",
        "X_train = [sent2features(s) for s in train_sentences]\n",
        "y_train = [sent2labels(s) for s in train_sentences]\n",
        "\n",
        "X_dev = [sent2features(s) for s in dev_sentences]\n",
        "y_dev = [sent2labels(s) for s in dev_sentences]\n",
        "\n",
        "X_test = [sent2features(s) for s in test_sentences]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UleMIHP0X6Q2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating the CRF model\n",
        "crf = CRF(algorithm='lbfgs',\n",
        "          c1=0.1,\n",
        "          c2=0.1,\n",
        "          max_iterations=100,\n",
        "          all_possible_transitions=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5xOekAmX9V8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crf = crf.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzYVpfgI1ed2",
        "colab_type": "code",
        "outputId": "e9c5da60-1fde-4627-a001-d83362270b2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "pred = cross_val_predict(estimator=crf, X = X_train,y = y_train, cv=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwRdHqK72JXv",
        "colab_type": "code",
        "outputId": "cae003ac-b175-4afa-dc92-d860da03b174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "#evaluate the model\n",
        "report = flat_classification_report(y_pred=pred, y_true=y_train)\n",
        "print(report)\n",
        "# f1 = metrics.flat_f1_score(y_train, y_pred, average='weighted', labels=labels)\n",
        "# print(\"F1 weighted avg: \" + str(f1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   B-company       0.88      0.43      0.58       171\n",
            "     B-group       0.68      0.16      0.26       106\n",
            "  B-location       0.77      0.54      0.63       380\n",
            "     B-other       0.55      0.23      0.32       225\n",
            "    B-person       0.78      0.63      0.70       449\n",
            "   B-product       0.83      0.15      0.26        97\n",
            "     B-title       0.59      0.19      0.29        68\n",
            "   I-company       0.50      0.08      0.14        36\n",
            "     I-group       0.60      0.14      0.23        84\n",
            "  I-location       0.62      0.34      0.44       154\n",
            "     I-other       0.51      0.29      0.37       320\n",
            "    I-person       0.77      0.72      0.74       215\n",
            "   I-product       0.74      0.17      0.28        80\n",
            "     I-title       0.56      0.19      0.29        77\n",
            "           O       0.97      1.00      0.98     44006\n",
            "\n",
            "    accuracy                           0.96     46468\n",
            "   macro avg       0.69      0.35      0.43     46468\n",
            "weighted avg       0.96      0.96      0.96     46468\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POk26KMItTJs",
        "colab_type": "code",
        "outputId": "23e40413-6e1d-491e-9e5a-fe9c2f1d34ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# labels = list(crf.classes_)\n",
        "\n",
        "# labels.remove('O')\n",
        "print(labels)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['B-location', 'I-location', 'B-title', 'I-title', 'B-company', 'B-product', 'B-person', 'B-other', 'I-other', 'B-group', 'I-group', 'I-product', 'I-company', 'I-person']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybkKJgm949gA",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bQ09BiitZR4",
        "colab_type": "code",
        "outputId": "0040e43e-cfaa-4d24-e739-9d1098c35511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred = crf.predict(X_dev)\n",
        "metrics.flat_f1_score(y_dev, y_pred,\n",
        "                      average='weighted', labels=labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.29913491761344696"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 398
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6QeV_Ottu5O",
        "colab_type": "code",
        "outputId": "b959e70c-17f9-4724-abec-d3c1f85cca98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "# group B and I results\n",
        "sorted_labels = sorted(\n",
        "    labels,\n",
        "    key=lambda name: (name[1:], name[0])\n",
        ")\n",
        "print(metrics.flat_classification_report(\n",
        "    y_dev, y_pred, labels=sorted_labels, digits=3\n",
        "))\n",
        "\n",
        "accuracy = metrics.flat_accuracy_score(y_dev, y_pred)\n",
        "print(\"Accuracy: \" + str(accuracy))\n",
        "f1 = metrics.flat_f1_score(y_dev, y_pred, average='weighted', labels=labels)\n",
        "precision = metrics.flat_precision_score(y_dev, y_pred, average='weighted', labels=labels)\n",
        "print(\"Precision : \"  + str(precision))\n",
        "print(\"Recall : \" + str(recall))\n",
        "recall = metrics.flat_recall_score(y_dev, y_pred, average='weighted', labels=labels)\n",
        "print(\"F1 weighted avg: \" + str(f1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   B-company      0.700     0.179     0.286        39\n",
            "   I-company      0.000     0.000     0.000        10\n",
            "     B-group      0.444     0.036     0.067       111\n",
            "     I-group      0.222     0.042     0.070        48\n",
            "  B-location      0.609     0.435     0.508       154\n",
            "  I-location      0.569     0.358     0.439        81\n",
            "     B-other      0.462     0.136     0.211       132\n",
            "     I-other      0.198     0.206     0.202        97\n",
            "    B-person      0.656     0.480     0.554       171\n",
            "    I-person      0.609     0.589     0.599        95\n",
            "   B-product      0.000     0.000     0.000        37\n",
            "   I-product      0.000     0.000     0.000       121\n",
            "     B-title      0.167     0.059     0.087        17\n",
            "     I-title      0.111     0.067     0.083        15\n",
            "\n",
            "   micro avg      0.507     0.254     0.339      1128\n",
            "   macro avg      0.339     0.185     0.222      1128\n",
            "weighted avg      0.427     0.254     0.299      1128\n",
            "\n",
            "Accuracy: 0.9407134071340714\n",
            "Precision : 0.4271204859938738\n",
            "Recall : 0.28634751773049644\n",
            "F1 weighted avg: 0.29913491761344696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncsWQQu1xMJu",
        "colab_type": "text"
      },
      "source": [
        "# Hyper Parameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4_KUUszxQie",
        "colab_type": "code",
        "outputId": "d47d6f6a-a1f6-4d68-af47-53ec98f260aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "Model_X = CRF(\n",
        "    algorithm='lbfgs',\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "params_space = {\n",
        "    'c1': scipy.stats.expon(scale=0.5),\n",
        "    'c2': scipy.stats.expon(scale=0.05),\n",
        "}\n",
        "\n",
        "# use the same metric for evaluation\n",
        "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
        "                        average='weighted', labels=labels)\n",
        "\n",
        "# search\n",
        "rs = RandomizedSearchCV(crf, params_space,\n",
        "                        cv=3,\n",
        "                        verbose=1,\n",
        "                        n_jobs=-1,\n",
        "                        n_iter=50,\n",
        "                        scoring=f1_scorer)\n",
        "rs.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  9.3min\n",
            "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 29.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
              "                                 all_possible_transitions=False, averaging=None,\n",
              "                                 c=None, c1=0.1, c2=0.1,\n",
              "                                 calibration_candidates=None,\n",
              "                                 calibration_eta=None,\n",
              "                                 calibration_max_trials=None,\n",
              "                                 calibration_rate=None,\n",
              "                                 calibration_samples=None, delta=None,\n",
              "                                 epsilon=None, error_sensitive=None, gamma=None,\n",
              "                                 keep_t...\n",
              "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fac9639e240>},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False,\n",
              "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=['B-location', 'I-location', 'B-title', 'I-title', 'B-company', 'B-product', 'B-person', 'B-other', 'I-other', 'B-group', 'I-group', 'I-product', 'I-company', 'I-person']),\n",
              "                   verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 400
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en-V95Voyknk",
        "colab_type": "text"
      },
      "source": [
        "# Best Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNKWqjduynlm",
        "colab_type": "code",
        "outputId": "98b1b9f8-cd9b-4819-8909-daf97617610f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print('best params:', rs.best_params_)\n",
        "print('best CV score:', rs.best_score_)\n",
        "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best params: {'c1': 0.09894864874708563, 'c2': 0.008322715163805268}\n",
            "best CV score: 0.4580033402173682\n",
            "model size: 0.35M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx3EuRlo5kvv",
        "colab_type": "code",
        "outputId": "69cea04a-2ad9-4fc2-999b-6325f1e62b0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "crf = rs.best_estimator_\n",
        "y_pred = crf.predict(X_dev)\n",
        "print(metrics.flat_classification_report(\n",
        "    y_dev, y_pred, labels=sorted_labels, digits=3\n",
        "))\n",
        "\n",
        "accuracy = metrics.flat_accuracy_score(y_dev, y_pred)\n",
        "print(\"accuracy :\" + str(accuracy))\n",
        "precision = metrics.flat_precision_score(y_dev, y_pred, average='weighted', labels=labels)\n",
        "print(\"Precision : \"  + str(precision))\n",
        "recall = metrics.flat_recall_score(y_dev, y_pred, average='weighted', labels=labels)\n",
        "print(\"Recall : \" + str(recall))\n",
        "f1 = metrics.flat_f1_score(y_dev, y_pred, average='weighted', labels=labels)\n",
        "print(\"F1 weighted avg: \" + str(f1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   B-company      0.615     0.205     0.308        39\n",
            "   I-company      0.000     0.000     0.000        10\n",
            "     B-group      0.375     0.027     0.050       111\n",
            "     I-group      0.000     0.000     0.000        48\n",
            "  B-location      0.589     0.429     0.496       154\n",
            "  I-location      0.561     0.395     0.464        81\n",
            "     B-other      0.429     0.159     0.232       132\n",
            "     I-other      0.169     0.227     0.194        97\n",
            "    B-person      0.629     0.515     0.566       171\n",
            "    I-person      0.580     0.611     0.595        95\n",
            "   B-product      0.667     0.054     0.100        37\n",
            "   I-product      0.000     0.000     0.000       121\n",
            "     B-title      0.250     0.118     0.160        17\n",
            "     I-title      0.182     0.133     0.154        15\n",
            "\n",
            "   micro avg      0.473     0.270     0.343      1128\n",
            "   macro avg      0.360     0.205     0.237      1128\n",
            "weighted avg      0.416     0.270     0.304      1128\n",
            "\n",
            "accuracy :0.9394833948339484\n",
            "Precision : 0.4158378998909514\n",
            "Recall : 0.2695035460992908\n",
            "F1 weighted avg: 0.30410170394291103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVLpN_ce61Ze",
        "colab_type": "code",
        "outputId": "cbf29b23-3629-442a-c13a-945ef6f06f78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "\n",
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
        "\n",
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top likely transitions:\n",
            "B-title -> I-title 8.119282\n",
            "B-location -> I-location 7.999295\n",
            "B-product -> I-product 7.899984\n",
            "B-group -> I-group 7.839663\n",
            "B-other -> I-other 7.575454\n",
            "I-title -> I-title 7.370144\n",
            "I-other -> I-other 7.103920\n",
            "I-product -> I-product 7.074475\n",
            "B-person -> I-person 6.957228\n",
            "I-group -> I-group 6.727056\n",
            "I-location -> I-location 6.245277\n",
            "B-company -> I-company 6.187699\n",
            "I-company -> I-company 5.520954\n",
            "I-person -> I-person 4.107069\n",
            "O      -> O       3.956403\n",
            "O      -> B-person 2.702857\n",
            "O      -> B-company 2.398870\n",
            "O      -> B-group 2.116452\n",
            "O      -> B-title 2.103919\n",
            "O      -> B-product 2.053674\n",
            "\n",
            "Top unlikely transitions:\n",
            "B-location -> B-other 0.413640\n",
            "I-location -> B-group 0.242053\n",
            "B-person -> O       0.170685\n",
            "I-company -> B-location 0.165424\n",
            "I-person -> O       0.146537\n",
            "B-company -> O       0.122398\n",
            "B-company -> B-location 0.004443\n",
            "I-location -> B-location -0.009856\n",
            "I-other -> O       -0.011795\n",
            "B-location -> O       -0.088287\n",
            "I-title -> O       -0.090715\n",
            "I-location -> O       -0.134749\n",
            "I-other -> B-person -0.260287\n",
            "I-company -> O       -0.263307\n",
            "B-group -> O       -0.272416\n",
            "I-product -> O       -0.288048\n",
            "B-other -> O       -0.288795\n",
            "I-group -> O       -0.337912\n",
            "B-product -> O       -0.527262\n",
            "B-title -> O       -1.174874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh3d0PMU7HpF",
        "colab_type": "code",
        "outputId": "0d509b12-0291-4803-a1a9-006344f1ab9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def print_state_features(state_features):\n",
        "    for (attr, label), weight in state_features:\n",
        "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
        "\n",
        "print(\"Top positive:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common(30))\n",
        "\n",
        "print(\"\\nTop negative:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top positive:\n",
            "12.361380 B-company stem:twitter\n",
            "11.444681 B-person stem:pope\n",
            "10.371792 B-product stem:iphon\n",
            "9.554440 B-company stem:facebook\n",
            "9.345045 B-other  stem:xma\n",
            "9.303597 B-person stem:4dbling\n",
            "8.977755 B-product stem:ipod\n",
            "8.847905 B-other  stem:ebgp\n",
            "8.367108 B-company stem:youtub\n",
            "8.345653 B-company stem:walmart\n",
            "8.239830 B-other  stem:christma\n",
            "8.138001 B-other  stem:dynamit\n",
            "8.108571 B-other  stem:dem\n",
            "8.108231 B-company stem:mcdonald\n",
            "8.081373 B-company stem:wipro\n",
            "7.919225 B-product +1:stem:devic\n",
            "7.911177 B-group  stem:indigen\n",
            "7.907480 B-location stem:lh\n",
            "7.778233 B-person stem:sfitzy93\n",
            "7.699673 B-location stem:jupit\n",
            "7.676702 B-product stem:pringl\n",
            "7.645453 B-location stem:mv\n",
            "7.642943 B-company stem:yahoo\n",
            "7.610326 B-person stem:o.d.b.\n",
            "7.403901 B-title  stem:gigli\n",
            "7.310880 B-person stem:jfk\n",
            "7.296390 B-person stem:eminem\n",
            "7.219710 B-person stem:madi\n",
            "7.059827 O        stem:tuesday\n",
            "7.036540 B-product stem:iphone4\n",
            "\n",
            "Top negative:\n",
            "-2.563158 O        +1:stem:song\n",
            "-2.564631 O        stem:rose\n",
            "-2.565312 O        +1:stem:concert\n",
            "-2.580019 O        +1:stem:footbal\n",
            "-2.616348 O        stem:of\n",
            "-2.616745 O        +1:stem:@\n",
            "-2.628166 O        +1:stem:power\n",
            "-2.681148 O        -1:stem:king\n",
            "-2.681492 O        stem:fb\n",
            "-2.694540 O        -1:stem:manag\n",
            "-2.719162 O        +1:stem:state\n",
            "-2.741831 O        +1:stem:V\n",
            "-2.755141 O        +1:stem:famili\n",
            "-2.848194 O        -1:stem:13\n",
            "-2.912696 O        +1:stem:!!!!!!!\n",
            "-2.946170 O        -1:stem:then\n",
            "-2.998498 O        stem:london\n",
            "-3.045809 O        -1:stem:beat\n",
            "-3.085616 O        -1:stem:purchas\n",
            "-3.109106 O        stem:lush\n",
            "-3.173314 I-location -1:inLocations\n",
            "-3.241517 O        +1:stem:knw\n",
            "-3.343812 O        stem:tumblr\n",
            "-3.377874 O        -1:stem:silli\n",
            "-3.511231 O        hasCapitalLetter\n",
            "-3.524944 O        +1:stem:sign\n",
            "-3.532578 O        stem:inform\n",
            "-3.698988 O        -1:stem:hate\n",
            "-4.268410 O        stem:itun\n",
            "-4.769412 O        stem:ipad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8OxPL0ZNKgz",
        "colab_type": "code",
        "outputId": "7f94ad96-f568-4886-e8e7-5186fbfcb790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "crf = rs.best_estimator_\n",
        "y_pred = crf.predict(X_test)\n",
        "print(y_pred[0][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNi_HAyDT8lb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outF = open(\"result.txt\", \"w\")\n",
        "outR = open(\"test_no_tag.txt\", \"r\")\n",
        "lines = outR.readlines()\n",
        "\n",
        "line_num = 0\n",
        "for list in y_pred:\n",
        "    for x in list:\n",
        "      if len(lines[line_num])>0:        \n",
        "        outF.write(lines[line_num].replace(\"\\n\",\"\")+\"\\t\\t\\t\" + x +\"\\n\")\n",
        "       \n",
        "      line_num = line_num + 1\n",
        "outF.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57o2LDnds9iW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}